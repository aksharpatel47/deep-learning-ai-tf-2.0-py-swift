{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization with Tensorflow 2.0\n",
    "\n",
    "Andrew Ng's deeplearning.ai Coursera course starts with talking about how using vectorized operations instead of for loops can drastically improve the performance of machine learning and deep learning computations. The course talks about implementing functions such as sigmoid, softmax and more using Numpy. In this series, we'll go through implementing the entire deeplearning.ai using tensorflow 2.0. This post talks about implementing vector operations using the tensorflow framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if a gpu is available to perform the vector operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "a = tf.constant([10, 2, 3, 4])\n",
    "b = tf.constant([2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=186, shape=(4,), dtype=int32, numpy=array([12,  5,  7,  9])>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The add function of tensorflow can also be used to add an array and a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=188, shape=(4,), dtype=int32, numpy=array([11,  3,  4,  5])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying / Dividing an array with a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=190, shape=(4,), dtype=int32, numpy=array([20,  4,  6,  8])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=194, shape=(4,), dtype=float64, numpy=array([5. , 1. , 1.5, 2. ])>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.divide(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing a dot product\n",
    "\n",
    "A dot product for two arrays using numpy is very easy. It can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing a dot product using tensorflow\n",
    "\n",
    "We can use matrix multiplication to do dot product between the two arrays. However, before doing matrix multiplication you need to reshape the arrays to explicitly shape them from (x,) shape to (1, x) shape for the first array and from (x,) shape to (x, 1) shape for the the second array. This will make the end result to be a (1,1) array giving us the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = tf.matmul(tf.reshape(a, (1, 4)), tf.reshape(b, (4, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=199, shape=(1, 1), dtype=int32, numpy=array([[58]])>,\n",
       " TensorShape([1, 1]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod, prod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squaring an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=200, shape=(4,), dtype=int32, numpy=array([100,   4,   9,  16])>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing up all values in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = tf.reduce_sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the value of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce sum works similarly for matrices as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=209, shape=(), dtype=int32, numpy=33>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum([a, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing a matrix multiplication\n",
    "\n",
    "matmul function of tensorflow is used for doing matrix multiplication. Before doing the matrix multiplication, care must be taken to make sure that the matrices are multipliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=214, shape=(4, 4), dtype=int32, numpy=\n",
       "array([[20, 30, 40, 50],\n",
       "       [ 4,  6,  8, 10],\n",
       "       [ 6,  9, 12, 15],\n",
       "       [ 8, 12, 16, 20]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.reshape(a, (4, 1)), tf.reshape(b, (1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecing the device (CPU/GPU) on which to perform the vector operations\n",
    "\n",
    "To select the device we use the compute the vector operations, we use the context of the device as follows:\n",
    "\n",
    "```python\n",
    "with tf.device(\"CPU:0\") # or GPU:0 if we want to run it on a gpu\n",
    "    # vector operations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking large matrix operations on CPU and GPU\n",
    "\n",
    "To benchmark the performance of the vector operations running on CPU and GPU, we'll need a sufficiently large number where the GPU can shine. I've selected 10000 * 10000 shaped matrix with uniform random values. This matrix will be multiplied with itself and the performance will be measured. We'll select numpy matrix multiplication as a baseline to compare tensorflow's performance on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the matrix multiplication using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy CPU Time 10.08s\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(size=10000 *10000)\n",
    "x = x.reshape(10000, 10000)\n",
    "start = time.time()\n",
    "np.matmul(x, x)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Numpy CPU Time {0:.2f}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the matrix multiplication using TensorFlow on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n",
      "CPU Time: 4.86s\n"
     ]
    }
   ],
   "source": [
    "print(\"Running on CPU\")\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    x = tf.random.uniform([10000, 10000])\n",
    "    start = time.time()\n",
    "    tf.matmul(x, x)\n",
    "    end = time.time()\n",
    "\n",
    "print(\"CPU Time: {0:.2f}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the matrix multiplication using TensorFlow on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n",
      "GPU Time: 0.0s\n"
     ]
    }
   ],
   "source": [
    "print(\"Running on GPU\")\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    x = tf.random.uniform([10000, 10000])\n",
    "    start = time.time()\n",
    "    tf.matmul(x, x)\n",
    "    end = time.time()\n",
    "    \n",
    "print(\"GPU Time: {0}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"devices\": [\"Numpy CPU\", \"TF2 CPU\", \"TF2 GPU\"], \"performance\": [10.34, 5.16, 0.27]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(x = \"devices\", y = \"performance\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "As seen in the above graph, for such a massive calculation, using tensorflow 2.0 on GPU gives a massive boost in performance for the matrix multiplication operation. Even running the matrix multiplication operation on CPU using tensorflow reduces the time it takes to compute matmul by half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a sigmoid function\n",
    "\n",
    "Sigmoid is an activation function that returns the values between 0 and 1. The formula for the sigmoid function is as follows:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + \\exp^{-x}}\n",
    "$$\n",
    "\n",
    "Implementing that in TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Arguments:\n",
    "x -- a tensor\n",
    "\n",
    "Returns:\n",
    "tensor -- sigmoid computed for each value in tensor\n",
    "\"\"\"\n",
    "sigmoid = lambda x: 1 / (1 + tf.math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sigmoid(3.0) == 0.9525741268224334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104, shape=(3,), dtype=float64, numpy=array([0.73105858, 0.88079708, 0.95257413])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([1., 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a derivative of a sigmoid function\n",
    "\n",
    "$$\n",
    "s = \\sigma(x)\n",
    "\\\\\\sigma'(x) = s (1 - s)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x - a tensor\n",
    "    \n",
    "    Returns:\n",
    "    sigmoid_derivative -- sigmoid derivative computed for each value in tensor\n",
    "    \"\"\"\n",
    "    s = sigmoid(x)\n",
    "    ds = s * (1 - s)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=113, shape=(3,), dtype=float64, numpy=array([0.19661193, 0.10499359, 0.04517666])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([1., 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping a tensor\n",
    "\n",
    "We use the reshape function provided by TensorFlow to reshape a tensor to a particular shape. Let's say we want to reshape x of shape (3,) to (3, 1), we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=118, shape=(3, 1), dtype=int32, numpy=\n",
       "array([[1],\n",
       "       [2],\n",
       "       [3]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x, (3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we want to create a vector out of a matrix, we can use reshape for the operation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.constant([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, depth = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=121, shape=(18, 1), dtype=float32, numpy=\n",
       "array([[0.6782614 ],\n",
       "       [0.2938038 ],\n",
       "       [0.9071498 ],\n",
       "       [0.5283565 ],\n",
       "       [0.4215251 ],\n",
       "       [0.45017552],\n",
       "       [0.9281422 ],\n",
       "       [0.9667765 ],\n",
       "       [0.853047  ],\n",
       "       [0.52351844],\n",
       "       [0.19981398],\n",
       "       [0.27417314],\n",
       "       [0.60659856],\n",
       "       [0.00533165],\n",
       "       [0.10820313],\n",
       "       [0.49978936],\n",
       "       [0.3414428 ],\n",
       "       [0.94630075]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(image, (height * width * depth, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing a matrix\n",
    "\n",
    "In normalization, we change each row vector $x \\text{to} \\frac{x}{\\Vert x\\Vert}$ where $\\Vert x\\Vert$ is the norm of the row vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x -- a tensor\n",
    "    \n",
    "    Returns:\n",
    "    normalized_x\n",
    "    \"\"\"\n",
    "    # Calculating the norm. keepdims makes sure that the output tensor is not a first order tensor\n",
    "    x_norm = tf.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return tf.divide(x, x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=157, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.        , 0.6       , 0.8       ],\n",
       "       [0.13736056, 0.8241634 , 0.54944223]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_rows(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x -- a tensor\n",
    "    \n",
    "    Returns:\n",
    "    tensor -- softmax computed for each value in the input tensor\n",
    "    \"\"\"\n",
    "    x_exp = tf.exp(x)\n",
    "    x_sum = tf.reduce_sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / x_sum\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=164, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[9.80897605e-01, 8.94462864e-04, 1.79657657e-02, 1.21052377e-04,\n",
       "        1.21052377e-04],\n",
       "       [8.78679812e-01, 1.18916385e-01, 8.01252259e-04, 8.01252259e-04,\n",
       "        8.01252259e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing L1 and L2 loss function\n",
    "\n",
    "#### L1 Loss function equation\n",
    "$L_1(\\hat{y}, y) = \\sum_{i=0}^m|y^{(i)} - \\hat{y}^{(i)}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(ŷ, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ŷ -- vector of predicted labels of size m\n",
    "    y -- vector of groundtruth labels of size m\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the L1 loss as defined by the above formula\n",
    "    \"\"\"\n",
    "    loss = tf.reduce_sum(tf.abs(ŷ - y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = tf.constant([.9, 0.2, 0.1, .4, .9])\n",
    "y = tf.constant([1, 0, 0, 1, 1], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=177, shape=(), dtype=float32, numpy=1.1>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1(ŷ, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Loss function equation\n",
    "$L_2(\\hat{y},y) = \\sum_{i=0}^m(y^{(i)} - \\hat{y}^{(i)})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(ŷ, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ŷ -- vector of predicted labels of size m\n",
    "    y -- vector of groundtruth labels of size m\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the L2 loss as defined by the above formula\n",
    "    \"\"\"\n",
    "    loss = tf.reduce_sum(tf.square(ŷ - y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=181, shape=(), dtype=float32, numpy=0.43>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2(ŷ, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
